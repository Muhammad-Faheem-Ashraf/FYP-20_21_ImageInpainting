{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Testing_chroma.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayFbdSVLYN_c"
      },
      "source": [
        "\n",
        "# ChromaGAN\n",
        "%tensorflow_version 1.x\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import tensorflow as tf\n",
        "from keras import applications\n",
        "from keras.models import load_model\n",
        "from google.colab.patches import cv2_imshow\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "# DIRECTORY INFORMATION\n",
        "DATA_DIR = os.path.join('/content/images/')\n",
        "OUT_DIR = os.path.join('/content/')\n",
        "MODEL_DIR = os.path.join('/content/gdrive/MyDrive/kaggle/MODEL/')\n",
        "# DATA INFORMATION\n",
        "BATCH_SIZE = 1\n",
        "# TRAINING INFORMATION\n",
        "PRETRAINED = \"my_model_colorization.h5\" \n",
        "\n",
        "class DATA():\n",
        "\n",
        "    def __init__(self, dirname):\n",
        "        self.dir_path =dirname\n",
        "        print(dirname)\n",
        "        self.filelist = os.listdir(self.dir_path )\n",
        "        self.batch_size = BATCH_SIZE\n",
        "        self.size = len(self.filelist)\n",
        "        self.data_index = 0\n",
        "\n",
        "    def read_img(self, filename):\n",
        "        IMAGE_SIZE = 224\n",
        "        print(filename)\n",
        "        img = cv2.imread(filename, 3)\n",
        "        height, width, channels = img.shape\n",
        "        labimg = cv2.cvtColor(cv2.resize(img, (IMAGE_SIZE, IMAGE_SIZE)), cv2.COLOR_BGR2Lab)\n",
        "        labimg_ori = cv2.cvtColor(img, cv2.COLOR_BGR2Lab)\n",
        "        return np.reshape(labimg[:,:,0], (IMAGE_SIZE, IMAGE_SIZE, 1)), labimg[:, :, 1:], img, np.reshape(labimg_ori[:,:,0], (height, width, 1))\n",
        "\n",
        "    def generate_batch(self):\n",
        "        batch = []\n",
        "        labels = []\n",
        "        filelist = []\n",
        "        labimg_oritList= []\n",
        "        originalList = [] \n",
        "        for i in range(self.batch_size):\n",
        "            filename = os.path.join(self.dir_path, self.filelist[self.data_index])\n",
        "            filelist.append(self.filelist[self.data_index])\n",
        "            greyimg, colorimg, original, labimg_ori = self.read_img(filename)\n",
        "            batch.append(greyimg)\n",
        "            labels.append(colorimg)\n",
        "            originalList.append(original)\n",
        "            labimg_oritList.append(labimg_ori)\n",
        "            self.data_index = (self.data_index + 1) % self.size\n",
        "        batch = np.asarray(batch)/255 # values between 0 and 1\n",
        "        labels = np.asarray(labels)/255 # values between 0 and 1\n",
        "        originalList = np.asarray(originalList)\n",
        "        labimg_oritList = np.asarray(labimg_oritList)/255\n",
        "        return batch, labels, filelist, originalList, labimg_oritList\n",
        "\n",
        "def deprocess(imgs):\n",
        "    imgs = imgs * 255\n",
        "    imgs[imgs > 255] = 255\n",
        "    imgs[imgs < 0] = 0\n",
        "    return imgs.astype(np.uint8)\n",
        "\n",
        "def reconstruct(batchX, predictedY):\n",
        "    result = np.concatenate((batchX, predictedY), axis=2)\n",
        "    result = cv2.cvtColor(result, cv2.COLOR_Lab2BGR)\n",
        "    return result\n",
        "\n",
        "def sample_images():\n",
        "    avg_ssim = 0\n",
        "    avg_psnr = 0\n",
        "    VGG_modelF = applications.vgg16.VGG16(weights='imagenet', include_top=True) \n",
        "    save_path = os.path.join(MODEL_DIR, PRETRAINED)\n",
        "    colorizationModel = load_model(save_path)\n",
        "    test_data = DATA(DATA_DIR)\n",
        "    assert test_data.size >= 0, \"Your list of images to colorize is empty. Please load images.\"\n",
        "    assert BATCH_SIZE<=test_data.size, \"The batch size (\" + str(BATCH_SIZE)+ \") should be smaller or equal to the number of testing images (\" + str(data_test.size)+ \") --> modify it\"\n",
        "    total_batch = int(test_data.size/BATCH_SIZE)\n",
        "    print(\"\")\n",
        "    print(\"number of images to colorize: \" + str(test_data.size))\n",
        "    print(\"total number of batches to colorize: \" + str(total_batch))\n",
        "    print(\"\")\n",
        "    if not os.path.exists(OUT_DIR):\n",
        "      print('created save result path')\n",
        "      os.makedirs(OUT_DIR)\n",
        "    for b in range(total_batch):\n",
        "            batchX, batchY, filelist, original, labimg_oritList = test_data.generate_batch()\n",
        "            predY, _ = colorizationModel.predict(np.tile(batchX,[1,1,1,3]))\n",
        "            predictVGG =VGG_modelF.predict(np.tile(batchX,[1,1,1,3]))\n",
        "            loss = colorizationModel.evaluate(np.tile(batchX,[1,1,1,3]), [batchY, predictVGG], verbose=0)\n",
        "            for i in range(BATCH_SIZE):\n",
        "                originalResult = original[i]\n",
        "                height, width, channels = originalResult.shape\n",
        "                predY_2 = deprocess(predY[i])\n",
        "                predY_2 = cv2.resize(predY_2, (width,height))\n",
        "                labimg_oritList_2 =labimg_oritList[i]\n",
        "                predResult_2= reconstruct(deprocess(labimg_oritList_2), predY_2)\n",
        "                ssim= tf.keras.backend.eval( tf.image.ssim(tf.convert_to_tensor(originalResult, dtype=tf.float32), tf.convert_to_tensor(predResult_2, dtype=tf.float32), max_val=255))\n",
        "                psnr= tf.keras.backend.eval( tf.image.psnr(tf.convert_to_tensor(originalResult, dtype=tf.float32), tf.convert_to_tensor(predResult_2, dtype=tf.float32), max_val=255))\n",
        "                avg_ssim += ssim\n",
        "                avg_psnr += psnr\n",
        "                save_path = os.path.join(OUT_DIR, \"{:.8f}_\".format(psnr)+filelist[i][:-4] +\"_reconstructed.jpg\" )\n",
        "                cv2_imshow(np.concatenate((np.tile(labimg_oritList[i]*255,[1,1,3]), predResult_2, originalResult),axis=1))\n",
        "                cv2.imwrite(save_path, predResult_2)\n",
        "                print(\"\")\n",
        "                print(\"Image \" + str(i+1) + \"/\" +str(BATCH_SIZE) + \" in batch \" + str(b+1) + \"/\" +str(total_batch) + \". From left to right: grayscale image to colorize, colorized image ( PSNR =\", \"{:.8f}\".format(psnr),\")\")\n",
        "                print(\"and ground truth image. Notice that PSNR has no sense in original black and white images.\")\n",
        "                print(\"\")\n",
        "                print(\"\")\n",
        "\n",
        "    print(\"average ssim loss =\", \"{:.8f}\".format(avg_ssim/(total_batch*BATCH_SIZE)))\n",
        "    print(\"average psnr loss =\", \"{:.8f}\".format(avg_psnr/(total_batch*BATCH_SIZE)))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    sample_images()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}