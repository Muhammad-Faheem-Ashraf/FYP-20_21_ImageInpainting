{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import Required libraries\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2021-07-26T16:24:59.83167Z","iopub.execute_input":"2021-07-26T16:24:59.832155Z","iopub.status.idle":"2021-07-26T16:25:00.036235Z","shell.execute_reply.started":"2021-07-26T16:24:59.83197Z","shell.execute_reply":"2021-07-26T16:25:00.035475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <font style=\"color:rgb(134,19,348)\"> Initialize the DNN module </font>\nTo use Models in ONNX format, you just have to use **`cv2.dnn.readNetFromONNX(model)`** and pass the model inside the function.","metadata":{}},{"cell_type":"code","source":"model = '../input/model1/super_resolution.onnx'\nnet = cv2.dnn.readNetFromONNX(model)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-26T16:28:49.353052Z","iopub.execute_input":"2021-07-26T16:28:49.353427Z","iopub.status.idle":"2021-07-26T16:28:49.364294Z","shell.execute_reply.started":"2021-07-26T16:28:49.353396Z","shell.execute_reply":"2021-07-26T16:28:49.362827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##  <font style=\"color:rgb(134,19,348)\">Read Image</font> ","metadata":{}},{"cell_type":"code","source":"# Read image\nimage = cv2.imread(\"../input/dipper/teenager.jpg\")\n\n# Display image\nplt.figure(figsize=[10,10])\nplt.imshow(image[:,:,::-1]);plt.axis('off');","metadata":{"execution":{"iopub.status.busy":"2021-07-26T16:25:00.087884Z","iopub.execute_input":"2021-07-26T16:25:00.088304Z","iopub.status.idle":"2021-07-26T16:25:00.37623Z","shell.execute_reply.started":"2021-07-26T16:25:00.088268Z","shell.execute_reply":"2021-07-26T16:25:00.375297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##  <font style=\"color:rgb(134,19,348)\"> Pre-processing the image \n</font>\nIn the this step we are going to Resize our image to (224x224) and convert it to YCbCr Color format. This format has following color components:\n\n- **Y:**  This is like the grayscale intensity channel, it holds all the image structure.\n- **Cb:** This is the blue-difference channel. \n- **Cr:** This is the red difference channel. \n\nAfter this we some formating of the Y channel and then finally normalize it by dividing with 255.0.","metadata":{}},{"cell_type":"code","source":"# Prepare the Image before fed into the network\n\n# Creating Copy of Image\nimg_copy = image.copy()\n\n# Resize the image into Required Size\nimg_copy = cv2.resize(img_copy, (224,224), cv2.INTER_CUBIC)\n\n# Convert image into YcbCr\nimage_YCbCr = cv2.cvtColor(img_copy, cv2.COLOR_BGR2YCrCb)\n\n# Split Y,Cb, and Cr channel \nimage_Y, image_Cb, image_Cr = cv2.split(image_YCbCr)\n\n# Covert Y channel into a numpy arrary\nimg_ndarray = np.asarray(image_Y)\n\n# Reshape the image to (1,1,224,224) \nreshaped_image = img_ndarray.reshape(1,1,224,224)\n\n# Convert to float32 and as a normalization step divide the image by 255.0\nblob = reshaped_image.astype(np.float32) / 255.0\n\nprint('initial Shape of Y: {}, Shape After Preprocessing: {}'.format(image_Y.shape, blob.shape))","metadata":{"execution":{"iopub.status.busy":"2021-07-26T16:25:00.377306Z","iopub.execute_input":"2021-07-26T16:25:00.377615Z","iopub.status.idle":"2021-07-26T16:25:00.399633Z","shell.execute_reply.started":"2021-07-26T16:25:00.377583Z","shell.execute_reply":"2021-07-26T16:25:00.398786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font style=\"color:rgb(134,19,348)\"> Input the Blob Image to the Network  </font>","metadata":{}},{"cell_type":"code","source":"# Passing the blob as input through the network \nnet.setInput(blob)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T16:25:00.402936Z","iopub.execute_input":"2021-07-26T16:25:00.403287Z","iopub.status.idle":"2021-07-26T16:25:00.408488Z","shell.execute_reply.started":"2021-07-26T16:25:00.403261Z","shell.execute_reply":"2021-07-26T16:25:00.407536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##  <font style=\"color:rgb(134,19,348)\">Forward Pass</font> \n","metadata":{}},{"cell_type":"code","source":"%%time\nOutput = net.forward()","metadata":{"execution":{"iopub.status.busy":"2021-07-26T16:25:00.410723Z","iopub.execute_input":"2021-07-26T16:25:00.411324Z","iopub.status.idle":"2021-07-26T16:25:00.618752Z","shell.execute_reply.started":"2021-07-26T16:25:00.411212Z","shell.execute_reply":"2021-07-26T16:25:00.617233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Our iamge has been resized to 672, a 3x increase.\nprint(Output.shape)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-26T16:25:00.620002Z","iopub.execute_input":"2021-07-26T16:25:00.620351Z","iopub.status.idle":"2021-07-26T16:25:00.626995Z","shell.execute_reply.started":"2021-07-26T16:25:00.620323Z","shell.execute_reply":"2021-07-26T16:25:00.624333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##  <font style=\"color:rgb(134,19,348)\"> Post-processing the image </font> \nWe got a 4D matrix as the output, now in the post-processing step you undo the steps you did in preprocessing.","metadata":{}},{"cell_type":"code","source":"# Reshape the output and get rid of those extra dimensions\nreshaped_output = Output.reshape(672,672)\n\n# Get the image back to the range 0-255 from 0-1\nreshaped_output = reshaped_output * 255\n\n# Clip the values so the output is it between 0-255\nFinal_Output = np.clip(reshaped_output, 0, 255)\n\n# Resize the Cb & Cr channel according to the output dimension\nresized_Cb = cv2.resize(image_Cb,(672,672),cv2.INTER_CUBIC)\nresized_Cr = cv2.resize(image_Cr,(672,672),cv2.INTER_CUBIC)\n\n# Merge all 3 channels together \nFinal_Img = cv2.merge((Final_Output.astype('uint8'), resized_Cb, resized_Cr))\n\n# Covert back to BGR channel\nFinal_Img = cv2.cvtColor(Final_Img,cv2.COLOR_YCR_CB2BGR)\nprint(Final_Img.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T16:25:00.628664Z","iopub.execute_input":"2021-07-26T16:25:00.629311Z","iopub.status.idle":"2021-07-26T16:25:00.649263Z","shell.execute_reply.started":"2021-07-26T16:25:00.62911Z","shell.execute_reply":"2021-07-26T16:25:00.648541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##  <font style=\"color:rgb(134,19,348)\">Display Final Result \n</font>","metadata":{}},{"cell_type":"code","source":"# This is how the image would look with Bicubic interpolation.\nimage_copy = cv2.resize(image,(672,672), cv2.INTER_CUBIC)\n\n# Display the Bicubic Image and Super Resolution Image\nplt.figure(figsize=[20,20])\nplt.subplot(1,2,1);plt.imshow(image_copy[:,:,::-1]);plt.title(\"Bicubic Interpolation\");plt.axis(\"off\");\nplt.subplot(1,2,2);plt.imshow(Final_Img[:,:,::-1]);plt.title(\"Super Resolution\");plt.axis(\"off\");","metadata":{"execution":{"iopub.status.busy":"2021-07-26T16:25:00.652095Z","iopub.execute_input":"2021-07-26T16:25:00.65233Z","iopub.status.idle":"2021-07-26T16:25:01.207158Z","shell.execute_reply.started":"2021-07-26T16:25:00.652308Z","shell.execute_reply":"2021-07-26T16:25:01.204547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font style=\"color:rgb(134,19,348)\"> Initialization Function </font>\nThis method will be run once and it will initialize the network with the required files.","metadata":{}},{"cell_type":"code","source":"def init_superres(model=\"Model/super_resolution.onnx\"):\n    # Set global variables\n    global net\n    \n    # Initialize the DNN module\n    net = cv2.dnn.readNetFromONNX(model)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T16:25:01.208568Z","iopub.execute_input":"2021-07-26T16:25:01.208958Z","iopub.status.idle":"2021-07-26T16:25:01.213707Z","shell.execute_reply.started":"2021-07-26T16:25:01.208921Z","shell.execute_reply":"2021-07-26T16:25:01.212579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font style=\"color:rgb(134,19,348)\">  Main Function </font>","metadata":{}},{"cell_type":"code","source":"def super_res(image,returndata=False):\n    \n    # Create a Copy of Image\n    img_copy = image.copy()\n\n    # Resize the image into Required Size\n    img_copy = cv2.resize(img_copy, (224,224), cv2.INTER_CUBIC)\n\n    # Convert image into YcbCr\n    image_YCbCr = cv2.cvtColor(img_copy, cv2.COLOR_BGR2YCrCb)\n\n    # Split Y,Cb, and Cr channel \n    image_Y, image_Cb, image_Cr = cv2.split(image_YCbCr)\n\n    # Covert Y channel into a numpy arrary\n    img_ndarray = np.asarray(image_Y)\n\n    # Reshape the image to (1,1,224,224) \n    reshaped_image = img_ndarray.reshape(1,1,224,224)\n\n    # Convert to float32 and as a normalization step divide the image by 255.0\n    blob = reshaped_image.astype(np.float32) / 255.0\n    \n    # Passing the blob as input through the network \n    net.setInput(blob)\n    \n    # Forward Pass\n    Output = net.forward()\n    \n    # Reshape the output and get rid of those extra dimensions\n    reshaped_output = Output.reshape(672,672)\n\n    # Get the image back to the range 0-255 from 0-1\n    reshaped_output = reshaped_output * 255\n\n    # Clip the values so the output is it between 0-255\n    Final_Output = np.clip(reshaped_output, 0, 255)\n\n    # Resize the Cb & Cr channel according to the output dimension\n    resized_Cb = cv2.resize(image_Cb,(672,672),cv2.INTER_CUBIC)\n    resized_Cr = cv2.resize(image_Cr,(672,672),cv2.INTER_CUBIC)\n\n    # Merge all 3 channels together \n    Final_Img = cv2.merge((Final_Output.astype('uint8'), resized_Cb, resized_Cr))\n\n    # Covert back to BGR channel\n    Final_Img = cv2.cvtColor(Final_Img,cv2.COLOR_YCR_CB2BGR)\n    \n    if  returndata:\n        return Final_Img\n    \n    else:\n        # This is how the image would look with Bicubic interpolation.\n        image_copy = cv2.resize(image,(672,672), cv2.INTER_CUBIC)\n        \n        # Display Image\n        plt.figure(figsize=[20,20])\n        plt.subplot(1,2,1);plt.imshow(image_copy[:,:,::-1]);plt.title(\"Bicubic Interpolation\");plt.axis(\"off\");\n        plt.subplot(1,2,2);plt.imshow(Final_Img[:,:,::-1]);plt.title(\"Super Resolution\");plt.axis(\"off\");       ","metadata":{"execution":{"iopub.status.busy":"2021-07-26T16:25:01.215165Z","iopub.execute_input":"2021-07-26T16:25:01.215559Z","iopub.status.idle":"2021-07-26T16:25:01.230407Z","shell.execute_reply.started":"2021-07-26T16:25:01.215528Z","shell.execute_reply":"2021-07-26T16:25:01.229277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Initialize the Super Resolution**","metadata":{}},{"cell_type":"code","source":"init_superres()","metadata":{"execution":{"iopub.status.busy":"2021-07-26T16:25:01.232319Z","iopub.execute_input":"2021-07-26T16:25:01.232888Z","iopub.status.idle":"2021-07-26T16:25:01.296892Z","shell.execute_reply.started":"2021-07-26T16:25:01.232852Z","shell.execute_reply":"2021-07-26T16:25:01.295588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Calling main function  temporary examples fahim ye add nhi ki hui mene***","metadata":{}},{"cell_type":"code","source":"image = cv2.imread(\"../input/dipper/teenager.jpg\")\nsuper_res(image)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T16:25:01.298096Z","iopub.status.idle":"2021-07-26T16:25:01.298501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image = cv2.imread(\"../input/dipper/oldman.jpg\")\nsuper_res(image)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T16:25:01.300033Z","iopub.status.idle":"2021-07-26T16:25:01.300716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image = cv2.imread(\"../input/dipper/youngman.jpg\")\nsuper_res(image)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T16:25:01.302173Z","iopub.status.idle":"2021-07-26T16:25:01.302845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image = cv2.imread(\"../input/dipper/youngman2.jpg\")\nsuper_res(image)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T16:25:01.304204Z","iopub.status.idle":"2021-07-26T16:25:01.304896Z"},"trusted":true},"execution_count":null,"outputs":[]}]}